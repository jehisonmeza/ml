{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plot\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargamos el dataset\n",
    "\n",
    "observa cómo convertimos la variable $y$ en **categórica**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension de los datos originales (1500, 785)\n",
      "(1500, 784) (1500,) (1500, 10)\n",
      "(1050, 784) (1050, 10) (450, 784) (450, 10)\n"
     ]
    }
   ],
   "source": [
    "mnist = np.loadtxt(\"data/mnist1.5k.csv\", delimiter=\",\")\n",
    "print \"dimension de los datos originales\", mnist.shape\n",
    "X=mnist[:,1:785]\n",
    "y=mnist[:,0]\n",
    "yc = tf.keras.utils.to_categorical(y)\n",
    "print X.shape, y.shape, yc.shape\n",
    "\n",
    "Xtr, Xts, ytr, yts = train_test_split(X,yc,test_size=.3)\n",
    "print Xtr.shape, ytr.shape, Xts.shape, yts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 1. 4. 0.]\n"
     ]
    }
   ],
   "source": [
    "print y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print yc[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creamos el modelo con  `keras`\n",
    "\n",
    "observa el número de parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 500)               100500    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 200)               100200    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 341,610\n",
      "Trainable params: 341,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_model_A():\n",
    "    tf.keras.backend.clear_session()\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, activation='tanh', input_dim=784))\n",
    "    model.add(Dense(200, activation='tanh'))\n",
    "    model.add(Dense(500, activation='tanh'))\n",
    "    model.add(Dense(200, activation='tanh'))\n",
    "    model.add(Dense(200, activation='tanh'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    model.reset_states()\n",
    "    return model\n",
    "\n",
    "model = get_model_A()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1050 samples, validate on 450 samples\n",
      "Epoch 1/40\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 1.3141 - acc: 0.5629 - val_loss: 0.8457 - val_acc: 0.7289\n",
      "Epoch 2/40\n",
      "1050/1050 [==============================] - 0s 456us/step - loss: 0.7186 - acc: 0.7657 - val_loss: 0.7762 - val_acc: 0.7444\n",
      "Epoch 3/40\n",
      "1050/1050 [==============================] - 0s 448us/step - loss: 0.5812 - acc: 0.8067 - val_loss: 0.7163 - val_acc: 0.7822\n",
      "Epoch 4/40\n",
      "1050/1050 [==============================] - 0s 453us/step - loss: 0.4898 - acc: 0.8533 - val_loss: 0.6664 - val_acc: 0.7956\n",
      "Epoch 5/40\n",
      "1050/1050 [==============================] - 0s 462us/step - loss: 0.4504 - acc: 0.8619 - val_loss: 0.6648 - val_acc: 0.7711\n",
      "Epoch 6/40\n",
      "1050/1050 [==============================] - 0s 468us/step - loss: 0.4024 - acc: 0.8705 - val_loss: 0.6614 - val_acc: 0.7956\n",
      "Epoch 7/40\n",
      "1050/1050 [==============================] - 1s 506us/step - loss: 0.3983 - acc: 0.8629 - val_loss: 0.7287 - val_acc: 0.7800\n",
      "Epoch 8/40\n",
      "1050/1050 [==============================] - 1s 617us/step - loss: 0.4573 - acc: 0.8476 - val_loss: 0.7989 - val_acc: 0.7533\n",
      "Epoch 9/40\n",
      "1050/1050 [==============================] - 1s 576us/step - loss: 0.5466 - acc: 0.8152 - val_loss: 0.8331 - val_acc: 0.7489\n",
      "Epoch 10/40\n",
      "1050/1050 [==============================] - 1s 655us/step - loss: 0.4815 - acc: 0.8371 - val_loss: 0.7338 - val_acc: 0.7822\n",
      "Epoch 11/40\n",
      "1050/1050 [==============================] - 1s 799us/step - loss: 0.3901 - acc: 0.8733 - val_loss: 0.7157 - val_acc: 0.7822\n",
      "Epoch 12/40\n",
      "1050/1050 [==============================] - 1s 954us/step - loss: 0.3351 - acc: 0.8819 - val_loss: 0.7067 - val_acc: 0.8000\n",
      "Epoch 13/40\n",
      "1050/1050 [==============================] - 1s 709us/step - loss: 0.3037 - acc: 0.9114 - val_loss: 0.7453 - val_acc: 0.7867\n",
      "Epoch 14/40\n",
      "1050/1050 [==============================] - 1s 545us/step - loss: 0.2735 - acc: 0.9171 - val_loss: 0.6531 - val_acc: 0.8156\n",
      "Epoch 15/40\n",
      "1050/1050 [==============================] - 1s 593us/step - loss: 0.3114 - acc: 0.8933 - val_loss: 0.6392 - val_acc: 0.7933\n",
      "Epoch 16/40\n",
      "1050/1050 [==============================] - 1s 592us/step - loss: 0.2615 - acc: 0.9076 - val_loss: 0.5920 - val_acc: 0.8133\n",
      "Epoch 17/40\n",
      "1050/1050 [==============================] - 1s 630us/step - loss: 0.2246 - acc: 0.9143 - val_loss: 0.6341 - val_acc: 0.8222\n",
      "Epoch 18/40\n",
      "1050/1050 [==============================] - 1s 721us/step - loss: 0.2168 - acc: 0.9276 - val_loss: 0.6955 - val_acc: 0.8178\n",
      "Epoch 19/40\n",
      "1050/1050 [==============================] - 1s 532us/step - loss: 0.2785 - acc: 0.9133 - val_loss: 0.7610 - val_acc: 0.8089\n",
      "Epoch 20/40\n",
      "1050/1050 [==============================] - 1s 563us/step - loss: 0.2796 - acc: 0.9057 - val_loss: 0.6542 - val_acc: 0.8044\n",
      "Epoch 21/40\n",
      "1050/1050 [==============================] - 1s 514us/step - loss: 0.2380 - acc: 0.9152 - val_loss: 0.5951 - val_acc: 0.8244\n",
      "Epoch 22/40\n",
      "1050/1050 [==============================] - 1s 573us/step - loss: 0.2368 - acc: 0.9162 - val_loss: 0.6874 - val_acc: 0.7844\n",
      "Epoch 23/40\n",
      "1050/1050 [==============================] - 1s 669us/step - loss: 0.2602 - acc: 0.9114 - val_loss: 0.7256 - val_acc: 0.8022\n",
      "Epoch 24/40\n",
      "1050/1050 [==============================] - 1s 822us/step - loss: 0.2448 - acc: 0.9181 - val_loss: 0.7123 - val_acc: 0.8000\n",
      "Epoch 25/40\n",
      "1050/1050 [==============================] - 1s 683us/step - loss: 0.2582 - acc: 0.9076 - val_loss: 0.6857 - val_acc: 0.8022\n",
      "Epoch 26/40\n",
      "1050/1050 [==============================] - 1s 692us/step - loss: 0.2186 - acc: 0.9257 - val_loss: 0.8374 - val_acc: 0.7733\n",
      "Epoch 27/40\n",
      "1050/1050 [==============================] - 1s 806us/step - loss: 0.2524 - acc: 0.9076 - val_loss: 0.7733 - val_acc: 0.7867\n",
      "Epoch 28/40\n",
      "1050/1050 [==============================] - 1s 875us/step - loss: 0.2770 - acc: 0.9086 - val_loss: 0.8143 - val_acc: 0.7711\n",
      "Epoch 29/40\n",
      "1050/1050 [==============================] - 1s 965us/step - loss: 0.2577 - acc: 0.8981 - val_loss: 0.8401 - val_acc: 0.7711\n",
      "Epoch 30/40\n",
      "1050/1050 [==============================] - 1s 821us/step - loss: 0.2941 - acc: 0.8952 - val_loss: 0.8527 - val_acc: 0.7733\n",
      "Epoch 31/40\n",
      "1050/1050 [==============================] - 1s 609us/step - loss: 0.2924 - acc: 0.8886 - val_loss: 0.7644 - val_acc: 0.7889\n",
      "Epoch 32/40\n",
      "1050/1050 [==============================] - ETA: 0s - loss: 0.2831 - acc: 0.899 - 1s 571us/step - loss: 0.2903 - acc: 0.8981 - val_loss: 0.7447 - val_acc: 0.7933\n",
      "Epoch 33/40\n",
      "1050/1050 [==============================] - 1s 750us/step - loss: 0.2444 - acc: 0.9133 - val_loss: 0.7768 - val_acc: 0.7933\n",
      "Epoch 34/40\n",
      "1050/1050 [==============================] - 1s 640us/step - loss: 0.2733 - acc: 0.9010 - val_loss: 0.8050 - val_acc: 0.7889\n",
      "Epoch 35/40\n",
      "1050/1050 [==============================] - 1s 556us/step - loss: 0.3161 - acc: 0.8971 - val_loss: 0.7981 - val_acc: 0.7733\n",
      "Epoch 36/40\n",
      "1050/1050 [==============================] - 1s 612us/step - loss: 0.2702 - acc: 0.9038 - val_loss: 0.6831 - val_acc: 0.8133\n",
      "Epoch 37/40\n",
      "1050/1050 [==============================] - 1s 649us/step - loss: 0.2068 - acc: 0.9314 - val_loss: 0.6614 - val_acc: 0.8222\n",
      "Epoch 38/40\n",
      "1050/1050 [==============================] - 1s 735us/step - loss: 0.2205 - acc: 0.9267 - val_loss: 0.6743 - val_acc: 0.8222\n",
      "Epoch 39/40\n",
      "1050/1050 [==============================] - 1s 621us/step - loss: 0.2172 - acc: 0.9210 - val_loss: 0.6599 - val_acc: 0.8000\n",
      "Epoch 40/40\n",
      "1050/1050 [==============================] - 1s 631us/step - loss: 0.1838 - acc: 0.9390 - val_loss: 0.7699 - val_acc: 0.7867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a3c5c7210>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtr, ytr, epochs=40, batch_size=64, validation_data=(Xts, yts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Añadimos capas de regularización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 500)               100500    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 200)               100200    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 341,610\n",
      "Trainable params: 341,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_model_B():\n",
    "    tf.keras.backend.clear_session()\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, activation='tanh', input_dim=784))\n",
    "    model.add(Dropout(0.15))\n",
    "    model.add(Dense(200, activation='tanh'))\n",
    "    model.add(Dropout(0.15))\n",
    "    model.add(Dense(500, activation='tanh'))\n",
    "    model.add(Dropout(0.15))\n",
    "    model.add(Dense(200, activation='tanh'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(200, activation='tanh'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    model.reset_states()\n",
    "    return model\n",
    "\n",
    "model = get_model_B()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1050 samples, validate on 450 samples\n",
      "Epoch 1/50\n",
      "1050/1050 [==============================] - 3s 3ms/step - loss: 1.8647 - acc: 0.3562 - val_loss: 1.2516 - val_acc: 0.5667\n",
      "Epoch 2/50\n",
      "1050/1050 [==============================] - 1s 686us/step - loss: 1.1837 - acc: 0.6029 - val_loss: 0.8837 - val_acc: 0.6911\n",
      "Epoch 3/50\n",
      "1050/1050 [==============================] - 1s 696us/step - loss: 1.0214 - acc: 0.6571 - val_loss: 0.7864 - val_acc: 0.7156\n",
      "Epoch 4/50\n",
      "1050/1050 [==============================] - 1s 618us/step - loss: 0.9505 - acc: 0.6848 - val_loss: 0.8401 - val_acc: 0.7089\n",
      "Epoch 5/50\n",
      "1050/1050 [==============================] - 1s 778us/step - loss: 0.8440 - acc: 0.7010 - val_loss: 0.7276 - val_acc: 0.7556\n",
      "Epoch 6/50\n",
      "1050/1050 [==============================] - 1s 731us/step - loss: 0.8004 - acc: 0.7390 - val_loss: 0.6876 - val_acc: 0.8022\n",
      "Epoch 7/50\n",
      "1050/1050 [==============================] - 1s 671us/step - loss: 0.7860 - acc: 0.7333 - val_loss: 0.6326 - val_acc: 0.7911\n",
      "Epoch 8/50\n",
      "1050/1050 [==============================] - 1s 834us/step - loss: 0.7128 - acc: 0.7657 - val_loss: 0.5753 - val_acc: 0.8200\n",
      "Epoch 9/50\n",
      "1050/1050 [==============================] - 1s 700us/step - loss: 0.7609 - acc: 0.7457 - val_loss: 0.6723 - val_acc: 0.7911\n",
      "Epoch 10/50\n",
      "1050/1050 [==============================] - 1s 658us/step - loss: 0.7210 - acc: 0.7543 - val_loss: 0.6723 - val_acc: 0.7800\n",
      "Epoch 11/50\n",
      "1050/1050 [==============================] - 1s 688us/step - loss: 0.7699 - acc: 0.7305 - val_loss: 0.6627 - val_acc: 0.8067\n",
      "Epoch 12/50\n",
      "1050/1050 [==============================] - 1s 730us/step - loss: 0.7378 - acc: 0.7619 - val_loss: 0.6248 - val_acc: 0.8133\n",
      "Epoch 13/50\n",
      "1050/1050 [==============================] - 1s 874us/step - loss: 0.7115 - acc: 0.7676 - val_loss: 0.6710 - val_acc: 0.7933\n",
      "Epoch 14/50\n",
      "1050/1050 [==============================] - 1s 741us/step - loss: 0.6554 - acc: 0.7810 - val_loss: 0.6225 - val_acc: 0.8133\n",
      "Epoch 15/50\n",
      "1050/1050 [==============================] - 1s 753us/step - loss: 0.6811 - acc: 0.7552 - val_loss: 0.7418 - val_acc: 0.7622\n",
      "Epoch 16/50\n",
      "1050/1050 [==============================] - 1s 904us/step - loss: 0.7148 - acc: 0.7657 - val_loss: 0.6987 - val_acc: 0.7844\n",
      "Epoch 17/50\n",
      "1050/1050 [==============================] - 1s 842us/step - loss: 0.6820 - acc: 0.7790 - val_loss: 0.6739 - val_acc: 0.7911\n",
      "Epoch 18/50\n",
      "1050/1050 [==============================] - 1s 817us/step - loss: 0.6347 - acc: 0.7810 - val_loss: 0.5765 - val_acc: 0.8089\n",
      "Epoch 19/50\n",
      "1050/1050 [==============================] - 1s 791us/step - loss: 0.6812 - acc: 0.7762 - val_loss: 0.6300 - val_acc: 0.8067\n",
      "Epoch 20/50\n",
      "1050/1050 [==============================] - 1s 797us/step - loss: 0.6447 - acc: 0.7914 - val_loss: 0.6306 - val_acc: 0.8133\n",
      "Epoch 21/50\n",
      "1050/1050 [==============================] - 1s 706us/step - loss: 0.5940 - acc: 0.8095 - val_loss: 0.5824 - val_acc: 0.8356\n",
      "Epoch 22/50\n",
      "1050/1050 [==============================] - 1s 799us/step - loss: 0.5853 - acc: 0.8086 - val_loss: 0.5714 - val_acc: 0.8267\n",
      "Epoch 23/50\n",
      "1050/1050 [==============================] - 1s 847us/step - loss: 0.6377 - acc: 0.7867 - val_loss: 0.7794 - val_acc: 0.7733\n",
      "Epoch 24/50\n",
      "1050/1050 [==============================] - 1s 866us/step - loss: 0.6768 - acc: 0.7686 - val_loss: 0.6976 - val_acc: 0.7822\n",
      "Epoch 25/50\n",
      "1050/1050 [==============================] - 1s 835us/step - loss: 0.6566 - acc: 0.7800 - val_loss: 0.7040 - val_acc: 0.7889\n",
      "Epoch 26/50\n",
      "1050/1050 [==============================] - 1s 901us/step - loss: 0.6266 - acc: 0.7886 - val_loss: 0.6750 - val_acc: 0.7889\n",
      "Epoch 27/50\n",
      "1050/1050 [==============================] - 1s 799us/step - loss: 0.5534 - acc: 0.8133 - val_loss: 0.5667 - val_acc: 0.8133\n",
      "Epoch 28/50\n",
      "1050/1050 [==============================] - 1s 818us/step - loss: 0.5884 - acc: 0.8048 - val_loss: 0.6635 - val_acc: 0.7978\n",
      "Epoch 29/50\n",
      "1050/1050 [==============================] - 1s 757us/step - loss: 0.6118 - acc: 0.8019 - val_loss: 0.6419 - val_acc: 0.7978\n",
      "Epoch 30/50\n",
      "1050/1050 [==============================] - 1s 732us/step - loss: 0.5928 - acc: 0.8086 - val_loss: 0.6903 - val_acc: 0.7844\n",
      "Epoch 31/50\n",
      "1050/1050 [==============================] - 1s 937us/step - loss: 0.5785 - acc: 0.8038 - val_loss: 0.6668 - val_acc: 0.8000\n",
      "Epoch 32/50\n",
      "1050/1050 [==============================] - 1s 802us/step - loss: 0.5297 - acc: 0.8190 - val_loss: 0.5887 - val_acc: 0.8267\n",
      "Epoch 33/50\n",
      "1050/1050 [==============================] - 1s 858us/step - loss: 0.4961 - acc: 0.8362 - val_loss: 0.5560 - val_acc: 0.8556\n",
      "Epoch 34/50\n",
      "1050/1050 [==============================] - 1s 796us/step - loss: 0.5461 - acc: 0.8171 - val_loss: 0.5581 - val_acc: 0.8422\n",
      "Epoch 35/50\n",
      "1050/1050 [==============================] - 1s 841us/step - loss: 0.5563 - acc: 0.8105 - val_loss: 0.6068 - val_acc: 0.8178\n",
      "Epoch 36/50\n",
      "1050/1050 [==============================] - 1s 837us/step - loss: 0.5473 - acc: 0.8124 - val_loss: 0.6591 - val_acc: 0.8000\n",
      "Epoch 37/50\n",
      "1050/1050 [==============================] - 1s 782us/step - loss: 0.6149 - acc: 0.7962 - val_loss: 0.5573 - val_acc: 0.8489\n",
      "Epoch 38/50\n",
      "1050/1050 [==============================] - 1s 799us/step - loss: 0.6099 - acc: 0.8086 - val_loss: 0.5887 - val_acc: 0.8400\n",
      "Epoch 39/50\n",
      "1050/1050 [==============================] - 1s 858us/step - loss: 0.6234 - acc: 0.7924 - val_loss: 0.7028 - val_acc: 0.8022\n",
      "Epoch 40/50\n",
      "1050/1050 [==============================] - 1s 888us/step - loss: 0.6270 - acc: 0.7914 - val_loss: 0.6510 - val_acc: 0.8067\n",
      "Epoch 41/50\n",
      "1050/1050 [==============================] - 1s 878us/step - loss: 0.6075 - acc: 0.8010 - val_loss: 0.6037 - val_acc: 0.8067\n",
      "Epoch 42/50\n",
      "1050/1050 [==============================] - 1s 905us/step - loss: 0.5928 - acc: 0.7981 - val_loss: 0.6238 - val_acc: 0.8156\n",
      "Epoch 43/50\n",
      "1050/1050 [==============================] - 1s 869us/step - loss: 0.5698 - acc: 0.8133 - val_loss: 0.6546 - val_acc: 0.8133\n",
      "Epoch 44/50\n",
      "1050/1050 [==============================] - 1s 815us/step - loss: 0.6427 - acc: 0.7781 - val_loss: 0.6056 - val_acc: 0.8378\n",
      "Epoch 45/50\n",
      "1050/1050 [==============================] - 1s 860us/step - loss: 0.5555 - acc: 0.8295 - val_loss: 0.5850 - val_acc: 0.8356\n",
      "Epoch 46/50\n",
      "1050/1050 [==============================] - 1s 882us/step - loss: 0.5704 - acc: 0.8048 - val_loss: 0.7102 - val_acc: 0.8000\n",
      "Epoch 47/50\n",
      "1050/1050 [==============================] - 1s 974us/step - loss: 0.5627 - acc: 0.8067 - val_loss: 0.5523 - val_acc: 0.8333\n",
      "Epoch 48/50\n",
      "1050/1050 [==============================] - 1s 929us/step - loss: 0.5524 - acc: 0.8200 - val_loss: 0.5726 - val_acc: 0.8133\n",
      "Epoch 49/50\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.5066 - acc: 0.8210 - val_loss: 0.6070 - val_acc: 0.8178\n",
      "Epoch 50/50\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.5012 - acc: 0.8333 - val_loss: 0.5861 - val_acc: 0.8178\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a33effa90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtr, ytr,\n",
    "         batch_size=64,\n",
    "         epochs=50,\n",
    "         validation_data=(Xts, yts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
